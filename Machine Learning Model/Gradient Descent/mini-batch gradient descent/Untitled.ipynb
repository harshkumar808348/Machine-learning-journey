{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "984d0601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21512493",
   "metadata": {},
   "outputs": [],
   "source": [
    "X , y = load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1ce7f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X , y = load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "447eb1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10)\n",
      "(442,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4c35591",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test =  train_test_split(X,y ,test_size=0.2, random_state= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "234f67a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc6decd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  -9.15865318 -205.45432163  516.69374454  340.61999905 -895.5520019\n",
      "  561.22067904  153.89310954  126.73139688  861.12700152   52.42112238]\n",
      "151.88331005254167\n"
     ]
    }
   ],
   "source": [
    "print(reg.coef_)\n",
    "print(reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1ca1c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4399338661568968"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = reg.predict(X_test)\n",
    "r2_score(y_test , y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d651b73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class MBGdRegressor:\n",
    "    \n",
    "    def __init__(self, batch_size, learning_rate, epochs):\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs  # Fixed spelling from 'ephocs' to 'epochs'\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.intercept_ = 0\n",
    "        self.coef_ = np.ones(X_train.shape[1])\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            for j in range(int(X_train.shape[0] / self.batch_size)):\n",
    "                idx = random.sample(range(X_train.shape[0]), self.batch_size)\n",
    "                X_batch = X_train[idx]\n",
    "                y_batch = y_train[idx]\n",
    "                \n",
    "                y_hat = np.dot(X_batch, self.coef_) + self.intercept_  # Fixed 'self.coef_0' to 'self.coef_'\n",
    "                \n",
    "                intercept_der = -2 * np.sum(y_batch - y_hat)\n",
    "                self.intercept_ = self.intercept_ - (self.lr * intercept_der)\n",
    "                \n",
    "                coef_der = -2 * np.dot((y_batch - y_hat), X_batch)\n",
    "                self.coef_ = self.coef_ - (self.lr * coef_der)\n",
    "                \n",
    "            print(self.intercept_, self.coef_)\n",
    "    \n",
    "    def predict(self, X_test):  # Fixed spelling from 'precict' to 'predict'\n",
    "        return np.dot(X_test, self.coef_) + self.intercept_  # Fixed 'self_coef_' to 'self.coef_'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f1f643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbr = MBGdRegressor(batch_size = int(X_train.shape[0]/10 ) , learning_rate = 0.01 , epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fe7e2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157.44476339789557 [ 7.77243915 -1.2432557  15.24797368 13.85529976  7.11721483  5.47407233\n",
      " -7.4475026   8.97008128 16.9348376   9.57831307]\n",
      "147.30336298367382 [ 12.15464551  -1.10130497  30.63069512  24.93576815  12.94398441\n",
      "  10.21714452 -16.50151187  18.6329428   30.91044143  17.92221251]\n",
      "161.27956121592155 [ 16.19013379  -0.23234397  42.44651494  34.85776112  19.42957145\n",
      "  15.25793246 -23.85609977  27.61343145  44.79033806  25.77742058]\n",
      "143.85801589510135 [ 20.4027538   -0.71214336  54.45250296  43.54920614  24.25734442\n",
      "  18.39734721 -31.12170734  35.83129877  58.15940662  33.10674052]\n",
      "157.11572344823207 [ 23.6653207    0.79156036  67.09080437  52.25545922  27.66691426\n",
      "  20.9493592  -39.35285904  43.86341534  69.88765942  38.41804371]\n",
      "140.09745654617222 [ 27.40496428  -1.56265548  79.03279393  59.52147918  32.48862738\n",
      "  24.86673748 -46.90806769  51.6965626   81.99719195  44.32363981]\n",
      "152.05486990946542 [ 28.90203316  -2.08524239  91.84893369  67.26676509  34.93511902\n",
      "  26.18463614 -54.83168107  58.69804329  93.78564364  50.06995843]\n",
      "141.14232635484032 [ 32.43663628  -0.81336886 103.11037482  75.90601045  38.27936099\n",
      "  29.12914523 -61.79738052  66.35240032 103.45250727  57.93058326]\n",
      "159.02935646713024 [ 35.29735365  -1.0154852  112.73082379  84.560301    38.84240764\n",
      "  28.95710114 -69.33516453  71.68811619 113.92438663  63.25066708]\n",
      "149.47090227634308 [ 39.17436696  -1.84896254 123.27660142  91.71398161  41.23908907\n",
      "  30.21922181 -75.41168734  77.35090039 124.23720969  69.7613509 ]\n",
      "162.24958756458255 [ 41.74812458  -4.26492105 131.17928484  99.51516451  42.27660328\n",
      "  30.70913727 -81.38108412  82.03193478 132.3672215   72.64072211]\n",
      "157.5535134942825 [ 44.2170356   -3.40241657 140.63574553 106.26073056  42.75515196\n",
      "  30.74778183 -87.46065292  86.76061631 140.08030363  77.97598704]\n",
      "143.62335477184095 [ 47.01542685  -4.11135572 149.23475134 113.2617598   44.37415416\n",
      "  30.72538777 -90.63930553  90.72954224 148.07936537  83.70647868]\n",
      "149.66469640245606 [ 49.24246109  -3.81481921 157.45778319 118.61444849  45.76498676\n",
      "  31.43386841 -95.99222853  95.30509783 156.75426397  88.42807621]\n",
      "152.45712180027274 [ 49.20381964  -6.14875025 164.04663151 122.82447232  45.80421316\n",
      "  30.70250207 -99.43497057  97.63019174 163.05217053  91.29629931]\n",
      "146.5657459083193 [  50.0071911    -9.98394042  172.05712053  128.58935137   46.1652764\n",
      "   28.79081446 -102.80369891  100.25951662  171.95520586   92.15202065]\n",
      "157.3788933171985 [  53.43673824  -11.01838364  179.71593672  135.01702637   47.36425302\n",
      "   28.68597643 -106.07422808  103.09330553  179.33422572   94.59378744]\n",
      "157.49118288041495 [  54.63989933  -11.52479092  188.56613466  142.65946721   48.42665979\n",
      "   30.07552011 -113.04801092  109.1597416   186.75142107   98.43172223]\n",
      "160.11405938594677 [  57.47678923  -11.40835162  196.61062883  150.32673534   49.50165347\n",
      "   30.37527499 -117.49852211  112.92959117  193.96408033  103.18410187]\n",
      "152.90481556681027 [  57.69275702  -13.51902587  204.19780604  153.91344988   49.63614384\n",
      "   29.29561557 -121.6620852   115.69362487  201.21528301  106.08681552]\n",
      "126.91952830036787 [  59.75028932  -13.46566064  211.34761219  158.52272788   49.75381104\n",
      "   28.20577601 -124.26360947  117.33165487  207.02039493  107.72691646]\n",
      "160.02160402403047 [  60.75375286  -15.51794106  215.73142516  162.64068663   48.61447646\n",
      "   25.94120649 -126.36119232  117.73763149  211.95848664  108.48170243]\n",
      "153.95172045200982 [  60.44329067  -18.83401907  223.26089579  167.18029515   48.82286232\n",
      "   25.44752703 -128.98358975  119.6657416   216.96048315  109.81784995]\n",
      "153.08027842604477 [  60.61287798  -18.83701589  228.13191927  170.91411566   49.01894428\n",
      "   25.03221285 -132.38322054  122.19403097  221.80773914  111.38154185]\n",
      "159.93444162376653 [  62.17818007  -21.28245747  232.69377205  175.45750544   49.06927414\n",
      "   23.82005755 -133.68438832  123.14827681  226.2604558   111.27407662]\n",
      "153.4142181455376 [  62.76723631  -24.03597272  238.42028519  177.08799686   46.95840351\n",
      "   21.09746007 -137.50260891  124.41049349  231.30978429  112.38280107]\n",
      "147.9927247047394 [  62.56222413  -25.44021155  242.5904377   180.87807068   44.74838164\n",
      "   18.51708695 -140.93514376  125.67756643  235.57384788  112.53126388]\n",
      "153.42835403672152 [  61.58812098  -28.23742403  246.63288629  182.34039221   41.89184274\n",
      "   14.97961806 -143.04022216  125.66830702  239.67277494  111.94374386]\n",
      "163.38369383894312 [  62.00268939  -29.38004511  251.87029953  186.42436725   41.64879224\n",
      "   13.80932348 -145.11168686  126.94274666  243.89565137  114.81332746]\n",
      "147.27243342949154 [  61.33509753  -30.43756226  256.1810102   189.37374043   40.28710497\n",
      "   11.80304003 -147.67402904  128.15089213  247.69367375  115.05822085]\n",
      "151.21016608738395 [  61.80762796  -32.10858188  261.13966918  192.44903208   39.35224757\n",
      "    9.65483206 -149.54172987  128.69385434  252.80459108  115.42332081]\n",
      "151.73288811036704 [  60.5732159   -34.14260364  267.94324968  195.38615551   38.05759557\n",
      "    7.25244273 -152.66908005  130.01603735  258.33845074  116.22477207]\n",
      "148.96323511855303 [  61.75956164  -35.4241382   272.61488639  199.89921243   37.62361786\n",
      "    5.63227225 -153.68323302  130.33196178  262.607242    117.33099382]\n",
      "135.34872336197859 [  61.80253864  -38.5712229   277.36839585  201.82711456   35.6574489\n",
      "    2.94182208 -155.35751407  130.28512099  266.12656444  118.26708921]\n",
      "143.39512409235073 [  61.86532161  -37.70268218  281.51454141  204.83423735   36.12450377\n",
      "    3.04171488 -158.1255682   132.78416834  270.81299533  119.41995013]\n",
      "150.6921007672259 [  60.52538348  -40.91433344  287.95130465  207.9640417    35.9092154\n",
      "    0.93977418 -158.43096033  132.63321803  275.79238308  120.15695852]\n",
      "154.29682963806457 [  60.75591132  -42.06273295  293.34412177  211.97295277   35.21305336\n",
      "   -1.0104447  -159.86653469  133.11917071  280.26984126  121.80107657]\n",
      "156.20850963358953 [  60.71477982  -44.04671712  298.42388326  214.48351089   34.53637665\n",
      "   -2.82025994 -161.87048832  133.87980756  285.14390588  124.2106597 ]\n",
      "151.87614337612735 [  59.40708448  -46.19854499  304.07312441  217.73842754   33.25791203\n",
      "   -5.43850221 -162.15511324  133.06670988  288.62956963  123.98623717]\n",
      "155.00337996643015 [  58.29364632  -47.7002602   310.41258952  219.58818812   32.74181698\n",
      "   -6.59201894 -163.63102211  133.50733367  291.91916948  125.59193894]\n",
      "155.82575921626022 [  57.38726007  -49.57673558  314.64341471  221.69259353   30.81594286\n",
      "   -8.63657077 -165.98858805  133.91760788  294.73900079  125.65433585]\n",
      "147.76613189975635 [  55.29378582  -52.94134533  318.08706701  222.99247146   30.07125913\n",
      "  -10.02324704 -167.08248787  134.28888902  297.35926541  125.76982863]\n",
      "151.60629791063795 [  53.9210847   -55.19376974  320.66278183  224.51074204   29.25172434\n",
      "  -11.66134921 -168.10939134  134.37181337  300.08021765  125.17456195]\n",
      "151.70677198286202 [  54.47491123  -56.19755189  324.61805496  226.58004686   28.59535796\n",
      "  -12.26275678 -170.79643868  135.60729017  302.75505525  126.18068528]\n",
      "149.85532224288272 [  56.30540069  -58.59874185  328.16441306  228.98686492   28.03744994\n",
      "  -14.04187397 -170.11889528  134.25296397  305.21022371  128.49578375]\n",
      "156.73511090259444 [  56.84638624  -59.42549538  332.97473199  231.62750969   26.19635832\n",
      "  -16.61001401 -171.79800671  134.37004412  309.07438667  129.64023872]\n",
      "152.57646658786422 [  56.51115378  -60.46311846  335.99598617  232.08965231   23.96378524\n",
      "  -19.93630736 -173.87022552  134.35702788  312.97666171  128.25844967]\n",
      "161.7342398476997 [  54.26168976  -61.77956045  339.49788379  234.65511653   21.64542978\n",
      "  -22.88661229 -175.23103994  133.65124634  315.71358554  127.71461304]\n",
      "151.93929069927833 [  52.65871167  -65.86256895  342.32038037  234.74124616   21.24407468\n",
      "  -24.1891453  -174.88226667  132.6417237   318.56494021  127.06031951]\n",
      "169.2338937226903 [  53.4801362   -68.29774301  346.60193099  237.71056088   18.78728891\n",
      "  -27.39102389 -175.96588481  131.83361587  321.5915511   127.01639688]\n"
     ]
    }
   ],
   "source": [
    "mbr.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00ef334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mbr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aaf6d6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3819056079945303"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test , y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16dde9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0db515",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
